import soundcard as sc
import numpy as np
import torch
import time
import threading
import queue
import re
import tkinter as tk
from tkinter import ttk
from faster_whisper import WhisperModel
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… (SETTINGS)
# ==========================================
APP_NAME = "NUWA TRANSLATOR REAL TIME"
SAMPLE_RATE = 16000
CHUNK_DURATION = 1.5      
WHISPER_MODEL = "base"    # ÙŠÙ…ÙƒÙ† Ø±ÙØ¹Ù‡ Ø¥Ù„Ù‰ "small" Ø£Ùˆ "medium" Ù„Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¬Ù‡Ø§Ø²Ùƒ Ù‚ÙˆÙŠØ§Ù‹
TRANSLATE_MODEL = "Helsinki-NLP/opus-mt-en-ar"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
COMPUTE_TYPE = "float16" if DEVICE == "cuda" else "int8"

# Ø£ÙŠÙ‚ÙˆÙ†Ø© Ù…Ø¯Ù…Ø¬Ø© (ÙƒØ±Ø© Ø£Ø±Ø¶ÙŠØ©/ØªØ±Ø¬Ù…Ø©) Ù„Ø¶Ù…Ø§Ù† Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ Ø´Ø±ÙŠØ· Ø§Ù„Ù…Ù‡Ø§Ù…
ICON_BASE64 = """
R0lGODlhIAAgAPEBAAAAAP///wAAAAAAACH5BAEAAAIALAAAAAAgACAAAAKwhI+py+0Po5y02ouz
3rz7D4biSJbmiabqyrbuC8fyTNf2jef6zvf+DwwKhcQiccksEgoAowECAQEAOw==
"""

# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø£ØµÙˆØ§Øª ÙˆØ§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ (ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ®Ø±Ø¬Ù‡ Whisper)
SOUND_EVENTS = {
    "music": "ðŸŽµ [Ù…ÙˆØ³ÙŠÙ‚Ù‰] ðŸŽµ",
    "applause": "ðŸ‘ [ØªØµÙÙŠÙ‚] ðŸ‘",
    "laughter": "ðŸ˜‚ [Ø¶Ø­Ùƒ] ðŸ˜‚",
    "laughs": "ðŸ˜‚ [Ø¶Ø­Ùƒ] ðŸ˜‚",
    "sighs": "ðŸ’¨ [ØªÙ†Ù‡ÙŠØ¯Ø©]",
    "cheers": "ðŸŽ‰ [Ù‡ØªØ§Ù] ðŸŽ‰",
    "clears throat": "ðŸ—£ï¸ [Ù†Ø­Ù†Ø­Ø©]",
    "bell": "ðŸ”” [ØµÙˆØª Ø¬Ø±Ø³] ðŸ””"
}

# ==========================================
# 2. Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ (MAIN APP CLASS)
# ==========================================
class NuwaTranslatorApp:
    def __init__(self, root):
        self.root = root
        self.root.title(APP_NAME)
        self.root.geometry("450x220")
        self.root.resizable(False, False)
        self.root.configure(bg="#1A1A2E")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø© Ù„ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø© ÙˆØ´Ø±ÙŠØ· Ø§Ù„Ù…Ù‡Ø§Ù…
        try:
            self.icon_image = tk.PhotoImage(data=ICON_BASE64)
            self.root.iconphoto(True, self.icon_image)
        except Exception as e:
            print("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø©:", e)

        # Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆØ§Ù„Ø­Ø§Ù„Ø©
        self.is_running = False
        self.audio_queue = queue.Queue(maxsize=15)
        self.text_queue = queue.Queue(maxsize=15)
        
        # Ø³ÙŠØ§Ù‚ ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØª (Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªØ±Ø§Ø¨Ø·Ø©)
        self.transcription_context = "Translate accurately, keeping standard punctuation and grammar. "
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.whisper_model = None
        self.tokenizer = None
        self.translator = None
        self.overlay = None
        self.last_speech_time = time.time()

        self.setup_control_ui()

    def setup_control_ui(self):
        """Ø¨Ù†Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø·Ø§Ø¨Ø¹ Ø­Ø¯ÙŠØ«"""
        title = tk.Label(self.root, text=APP_NAME, font=("Segoe UI", 18, "bold"), fg="#0F3460", bg="#1A1A2E")
        title.config(fg="#E94560") # Ù„ÙˆÙ† Ù…Ù…ÙŠØ² Ù„Ù„Ø¹Ù†ÙˆØ§Ù†
        title.pack(pady=15)

        self.status_label = tk.Label(self.root, text="Ready to start.", font=("Segoe UI", 11), fg="#A2A2BD", bg="#1A1A2E")
        self.status_label.pack(pady=5)

        self.start_btn = tk.Button(self.root, text="â–¶ Start Translation", font=("Segoe UI", 12, "bold"), 
                                   bg="#0F3460", fg="white", activebackground="#E94560", 
                                   activeforeground="white", relief="flat", cursor="hand2", 
                                   command=self.toggle_translation)
        self.start_btn.pack(pady=15, ipadx=30, ipady=8)

    def toggle_translation(self):
        """ØªØ´ØºÙŠÙ„ / Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        if not self.is_running:
            self.is_running = True
            self.start_btn.config(text="â¹ Stop Translation", bg="#E94560", activebackground="#B71C1C")
            self.status_label.config(text="Loading AI Models... Please wait â³")
            self.root.update()
            
            threading.Thread(target=self.init_system, daemon=True).start()
        else:
            self.is_running = False
            self.start_btn.config(text="â–¶ Start Translation", bg="#0F3460", activebackground="#0F3460")
            self.status_label.config(text="Translation Stopped.")
            if self.overlay:
                self.overlay.destroy()
                self.overlay = None

    def init_system(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙØªØ­ Ø§Ù„Ù€ Overlay"""
        if self.whisper_model is None:
            self.whisper_model = WhisperModel(WHISPER_MODEL, device=DEVICE, compute_type=COMPUTE_TYPE, cpu_threads=8)
            self.tokenizer = AutoTokenizer.from_pretrained(TRANSLATE_MODEL)
            self.translator = AutoModelForSeq2SeqLM.from_pretrained(TRANSLATE_MODEL).to(DEVICE)
        
        self.status_label.config(text=f"System Active ðŸŸ¢ | Device: {DEVICE.upper()}")
        self.root.after(0, self.create_overlay)
        
        threading.Thread(target=self.audio_listener, daemon=True).start()
        threading.Thread(target=self.transcribe_worker, daemon=True).start()
        threading.Thread(target=self.translate_worker, daemon=True).start()
        threading.Thread(target=self.watchdog, daemon=True).start()

    def create_overlay(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„Ù…ØªØ±Ø§ÙƒØ¨Ø© (Overlay) Ø¨Ø´ÙƒÙ„ Ø£Ù†ÙŠÙ‚"""
        self.overlay = tk.Toplevel(self.root)
        self.overlay.overrideredirect(True)
        self.overlay.attributes("-topmost", True)
        self.overlay.attributes("-alpha", 0.90)
        self.overlay.configure(bg="#000000")

        self.en_var = tk.StringVar()
        self.ar_var = tk.StringVar()

        # Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù†Øµ
        frame = tk.Frame(self.overlay, bg="#000000")
        frame.pack(padx=20, pady=10)

        # Ø§Ù„Ù†Øµ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ (Ø±Ù…Ø§Ø¯ÙŠ Ù…Ø§Ø¦Ù„)
        self.en_label = tk.Label(frame, textvariable=self.en_var, font=("Segoe UI", 14, "italic"),
                            fg="#B0B0B0", bg="#000000", wraplength=1200, justify="center")
        self.en_label.pack(pady=(0, 5))

        # Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Ø£ÙƒØ¨Ø±ØŒ Ø£Ø¨ÙŠØ¶ Ù†Ø§ØµØ¹ Ù…Ø¹ Ù„Ù…Ø³Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©)
        self.ar_label = tk.Label(frame, textvariable=self.ar_var, font=("Tajawal", 24, "bold"),
                            fg="#FFFFFF", bg="#000000", wraplength=1200, justify="center")
        self.ar_label.pack()

        self.update_overlay_position()

    def update_overlay_position(self):
        """ØªØ­Ø¯ÙŠØ« Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„Ù…ØªØ±Ø§ÙƒØ¨Ø© Ù„ØªÙƒÙˆÙ† Ø£Ø³ÙÙ„ Ø§Ù„Ø´Ø§Ø´Ø© Ø¯Ø§Ø¦Ù…Ø§Ù‹"""
        if not self.overlay or not self.overlay.winfo_exists(): return
        self.overlay.update_idletasks()
        screen_w = self.overlay.winfo_screenwidth()
        screen_h = self.overlay.winfo_screenheight()
        w = self.overlay.winfo_reqwidth()
        h = self.overlay.winfo_reqheight()
        x = (screen_w - w) // 2
        y = screen_h - h - 80 # Ù…Ø³Ø§ÙØ© Ù…Ù† Ø§Ù„Ø£Ø³ÙÙ„
        self.overlay.geometry(f"+{x}+{y}")

    # ==========================================
    # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø£Ø­Ø¯Ø§Ø«
    # ==========================================
    def check_for_sound_events(self, text):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØµÙ Ø§Ù„Ø£ØµÙˆØ§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ Ù…Ø«Ù„ (music) Ø£Ùˆ [applause]"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§ Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
        tags = re.findall(r'[\(\[](.*?)[\)\]]', text.lower())
        for tag in tags:
            for key, emoji_text in SOUND_EVENTS.items():
                if key in tag:
                    return emoji_text
        return None

    def audio_listener(self):
        """Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… (Loopback)"""
        speaker = sc.default_speaker()
        mics = sc.all_microphones(include_loopback=True)
        loopback = next((m for m in mics if speaker.name in m.name), mics[0]) 

        chunk_frames = int(CHUNK_DURATION * SAMPLE_RATE)
        
        with loopback.recorder(samplerate=SAMPLE_RATE) as rec:
            while self.is_running:
                frames = rec.record(numframes=chunk_frames)
                if frames.ndim > 1:
                    frames = frames.mean(axis=1)
                
                audio_data = frames.astype(np.float32)
                volume_norm = np.linalg.norm(audio_data) * 10
                
                if volume_norm > 1.5: 
                    if not self.audio_queue.full():
                        self.audio_queue.put(audio_data)
                else:
                    time.sleep(0.05)

    def transcribe_worker(self):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù…Ø¹ Ø­Ù‚Ù† Ø§Ù„Ø³ÙŠØ§Ù‚"""
        while self.is_running:
            try:
                audio = self.audio_queue.get(timeout=1)
                # Ø­Ù‚Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù‡Ù†Ø§
                segments, _ = self.whisper_model.transcribe(
                    audio, language="en", task="transcribe", 
                    beam_size=1, temperature=0.0, vad_filter=True,
                    initial_prompt=self.transcription_context
                )
                
                text = " ".join([s.text.strip() for s in segments]).strip()
                
                if text:
                    self.last_speech_time = time.time()
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø¢Ø®Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Ù†Ø­ØªÙØ¸ Ø¨Ø¢Ø®Ø± 100 Ø­Ø±Ù Ù„Ø¹Ø¯Ù… Ø¥Ø±Ù‡Ø§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø©)
                    self.transcription_context = text[-100:] 

                    if not self.text_queue.full():
                        self.text_queue.put(text)
            except queue.Empty:
                continue
            except Exception as e:
                pass

    def translate_worker(self):
        """ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£ØµÙˆØ§Øª"""
        while self.is_running:
            try:
                en_text = self.text_queue.get(timeout=1)
                
                # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ø­Ø¯Ø§Ø« ØµÙˆØªÙŠØ© (Ù…ÙˆØ³ÙŠÙ‚Ù‰ØŒ ØªØµÙÙŠÙ‚ØŒ Ø§Ù„Ø®)
                sound_event = self.check_for_sound_events(en_text)
                
                self.root.after(0, self.en_var.set, en_text)
                
                if sound_event:
                    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¬Ø±Ø¯ ØµÙˆØªØŒ Ù†Ø¶Ø¹ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø© ÙˆÙ†ØªØ®Ø·Ù‰ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù„Ù„Ø³Ø±Ø¹Ø©
                    self.root.after(0, self.ar_var.set, sound_event)
                else:
                    # 2. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
                    inputs = self.tokenizer(en_text, return_tensors="pt", padding=True).to(DEVICE)
                    gen = self.translator.generate(**inputs, max_length=128, num_beams=1, use_cache=True)
                    ar_text = self.tokenizer.batch_decode(gen, skip_special_tokens=True)[0].strip()

                    self.root.after(0, self.ar_var.set, ar_text)

                self.root.after(0, self.update_overlay_position)

            except queue.Empty:
                continue
            except Exception as e:
                pass

    def watchdog(self):
        """Ø¥Ø®ÙØ§Ø¡ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ø¹Ø¯ 4 Ø«ÙˆØ§Ù†ÙŠ Ù…Ù† Ø§Ù„ØµÙ…Øª"""
        while self.is_running:
            time.sleep(0.5)
            if time.time() - self.last_speech_time > 4.0:
                if self.en_var.get() != "":
                    self.root.after(0, self.en_var.set, "")
                    self.root.after(0, self.ar_var.set, "")
                    self.root.after(0, self.update_overlay_position)

# ==========================================
# 4. Ù†Ù‚Ø·Ø© Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚ (ENTRY POINT)
# ==========================================
if __name__ == "__main__":
    root = tk.Tk()
    app = NuwaTranslatorApp(root)
    root.mainloop()